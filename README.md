<h1>100 Days of ML Code</h1>
<hr>
<h2>Day 0: 14th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Basic Setup of environment and enrollment in Udacity's Machine Learning intro course and completed Introduction videos.</p>
<h4>Thoughts:</h4>
<p>The course is amazing and excited about 100 days of ML Code.</p>
<h4>Link of Work:</h4>
<p>Just enrolled in this course: https://in.udacity.com/course/intro-to-machine-learning--ud120-india</p>
<hr>

<h2>Day 1: 15th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt how exactly gradient descent works with mathematical derivations and also learnt Naive bayes for classification and implemented using sklearn</p>
<h4>Thoughts:</h4>
<p>Gone crazy in mathematical proofs for gradient descent but very important to understand why we are doing everything and next sklearn is very easy to use.</p>
<hr>

<h2>Day 2: 16th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt and solved problems on Bayes rule and learnt it's applications. Started developing the mini project on naive bayes.</p>
<h4>Thoughts:</h4>
<p>Once J.K.Rowling published a book name under false author name but the computers were able to identify that it was her and it's exciting to know that it can be done using naive bayes.</p>
<hr>

<h2>Day 3: 17th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about McCulloh pits neuron, their advantages and disadvantages and moved on to perceptron and also learnt perceptron algorithm</p>
<h4>Thoughts:</h4>
<p>Thought that I could the complete project started on day:2 but I couldn't as the dataset was huge, so learnt moved onto deep learning and learnt the perceptron stuff.</p>
<hr>

<h2>Day 4: 18th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Set up the python 2.7 environment ans finally completed the mini project on naive bayes and acheived an accuracy of 97.32%</p>
<h4>Thoughts:</h4>
<p>The dataset was huge and it took much time to download and extract but it is good to do some mini projects as they clear the concepts.</p>
<hr>

<h2>Day 5: 19th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about linearly saperable boolean functions, Sigmoid neuron, the typical machine learning setup.</p>
<h4>Thoughts:</h4>
<p>Understood the need for using sigmoid neuron, and the basic machine learning things needed to solve any problem.</p>
<hr>

<h2>Day 6: 20th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about feed forward forward neural networks and how to learn the parameters the feed forward neural networks.</p>
<h4>Thoughts:</h4>
<p>It's interesting to learn how to apply gradient descent for multilayer neural networks and the proofs.</p>
<hr>

<h2>Day 7: 21st August 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about Entropy, Cross Entropy and their derivations and understood which loss function to choose depending on outputs.</p>
<h4>Thoughts:</h4>
<p>The deeper you go into deep learning the more it is confusing. It took so much time to understand the difference between entropy and cross entropy.</p>
<hr>


<h2>Day 8: 22nd August 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt the backpropagation intuition and the derivations of the gradent with respect to the output units.</p>
<h4>Thoughts:</h4>
<p>Really exciting to know how exaclty backpropagation works with mathematical derivations, but just completed on output layer need to still calculate with respect to hidden layers, weights and biases</p>
<hr>


<h2>Day 9: 23rd August 2018</h2>
<h4>Todays Progress:</h4>
<p>Started learning SVM's in Udacity's Intro to Machine Learning Course..</p>
<h4>Thoughts:</h4>
<p>I really have a lot of confusion with SVM's, need to understand them better.</p>
<hr>


<h2>Day 10: 24th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about linear SVM and coded using SKlearn.</p>
<h4>Thoughts:</h4>
<p>The linear svm is easy to understand but need to know about several parameters used in it.</p>
<hr>

<h2>Day 11: 25th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Completed learning SVM including non-linear, and also learnt about gamma and C parameter.</p>
<h4>Thoughts:</h4>
<p>Interesting to learn about various kernels, started doing a project on SVM.</p>
<hr>


<h2>Day 12: 26th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Successfully completed project using SVM, the same project done using naive bayes but svm gives an accuray more than 99%.</p>
<h4>Thoughts:</h4>
<p>SVM's really take a lot of time in training but ofcourse gave a good accuracy.</p>
<hr>

<h2>Day 13: 27th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Started learning Decision trees from Udacity's Intro to Machine Learning course, learnt about basic decision tree and coded using skklearn.</p>
<h4>Thoughts:</h4>
<p>Decision trees are more prone to overfitting, need to learn if there is any way to reduce that.</p>
<hr>

<h2>Day 14: 28th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about Entropy, Information Gain, Bias and Variance. Started building the project on Decision Trees</p>
<h4>Thoughts:</h4>
<p>Understood decision trees very clearly, they are just simple like if else blocks.</p>
<hr>

<h2>Day 15: 29th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Successfully completed the project on Decision trees(the same project done using naive bayes) and got an accuracy of 97%</p>
<h4>Thoughts:</h4>
<p>Decision trees might be overfitting if we have more features, but in general gives good results</p>
<hr>



<h2>Day 16: 30th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Intersted in developing a project on Breast cancer prediction, so started learning Flask to build backend</p>
<h4>Thoughts:</h4>
<p>Flask is very easy to learn and yet powerful, learnt basics quickly</p>
<hr>



<h2>Day 17: 31th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Started working on Breast cancer prediction, collected the data and done some preprocessing</p>
<h4>Thoughts:</h4>
<p>Lucky that most of the data is good, so made it easy to process</p>
<h4>Link to Data:</h4>
<p>https://www.kaggle.com/uciml/breast-cancer-wisconsin-data</p>
<hr>



<h2>Day 18: 1st September 2018</h2>
<h4>Todays Progress:</h4>
<p>Built complte Prediction using SVM and also built an API to make the requests to server</p>
<h4>Thoughts:</h4>
<p>Too complex in this step, tried with ANN but it is over fitting the model so used SVM</p>
<hr>



<h2>Day 19: 2nd September 2018</h2>
<h4>Todays Progress:</h4>
<p>Successfully completed the project including the frontend with bootstrap, working great and yields an accuracy of more than 98%</p>
<h4>Thoughts:</h4>
<p>It was really a wonderful experience to build the complete project. so happy</p>
<h4>Link to Work:</h4>
<p>https://github.com/SurajChinna/Breast-Cancer-Prediction<p>
<hr>


<h2>Day 20: 3rd September 2018</h2>
<h4>Todays Progress:</h4>
<p>Started building a project that could predict the relationship between two sentences of a paragraph and returns the percentage using wordnet</p>
<h4>Thoughts:</h4>
<p>I really know nothing about nltk and wordnet but still trying to build a project</p>
<hr>

<h2>Day 21: 4th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Woo! Successfully completed the project but that is not accurate but doing well</p>
<h4>Thoughts:</h4>
<p>Felt really tough to jump into project without knowing anythig but somehow managed to complete.</p>
<h4>Link to Work:</h4>
<p>https://github.com/SurajChinna/Breast-Cancer-Prediction<p>
<hr>


<h2>Day 22: 5th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt the basic concepts of KNN and how it works</p>
<h4>Thoughts:</h4>
<p>KNN is pretty easy just some math.</p>
<hr>


<h2>Day 23: 6th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Back into Udacity's Intro to Machine Learning course, started lesson datasets and learning about enron</p>
<h4>Thoughts:</h4>
<p>Enron was a huge organisation that went bankrupt and it is interesting to study the reasons of failure</p>
<hr>


<h2>Day 24: 7th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Just analysed the data-set of enron and various features</p>
<h4>Thoughts:</h4>
<p>Finally, done with enron and need to start Regression</p>
<hr>



<h2>Day 25: 8th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Started the lesson regression.</p>
<h4>Thoughts:</h4>
<p>Just looked how and where the regression is used.</p>
<hr>

<h2>Day 26: 9th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt in greater detail about regression, various evaluation metrics and differences between regression and classification.</p>
<h4>Thoughts:</h4>
<p>Regression is pretty easy but learnt only linear regression</p>
<hr>

<h2>Day 27: 10th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt evaluation metrics in Regression, and completed a small project that could fit the line between age and salary.</p>
<h4>Thoughts:</h4>
<p>Project was good but there were some outliers that disturbed the line so need to learn about outliers</p>
<hr>


<h2>Day 28: 11th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt some basic stuff about outliers and a simple algo to remove them.</p>
<h4>Thoughts:</h4>
<p>Outliers are really disturbing..need to do some project</p>
<hr>

<h2>Day 29: 12th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt and Written a Small practical code to identify and also remove outliers.</p>
<h4>Thoughts:</h4>
<p>It's a good experience to check and remove the outliers.</p>
<hr>


<h2>Day 30: 13th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Understood the KMeans algorithm for clustering and its limitations.</p>
<h4>Thoughts:</h4>
<p>KMeans is really basic but it makes a lot of mistakes due to initialisiations of centroids.</p>
<hr>


<h2>Day 31: 14th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Got more idea about KMeans and completed the mini project in clustering.</p>
<h4>Thoughts:</h4>
<p>need to learn feature scaling.</p>
<hr>


<h2>Day 32: 15th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Started Feature Scaling lesson in Udacity's Intro to Machine Learning course. Learnt what is feature scaling and it's implementation in sklearn</p>
<h4>Thoughts:</h4>
<p>Found feature scaling as a very important step for some algorithms like SVM and KMeans clustering.</p>
<hr>


<h2>Day 33: 16th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt when to apply feature scaling and completed the mini project on feature scaling</p>
<h4>Thoughts:</h4>
<p>Feature scaling can be confusing but pretty interesting.</p>
<hr>


<h2>Day 34: 17th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Started Text Learning lesson in Udacity and learnt about bag of words and how to represent them in sklearn</p>
<h4>Thoughts:</h4>
<p>It's really hard to deal with language and a lot of confusion. I have to dig deeper</p>
<hr>


<h2>Day 35: 18th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about stemmers and also learnt how to use them in sklearn and implemented SnowballStemmer</p>
<h4>Thoughts:</h4>
<p>feeling confident as going more into text learning</p>
<hr>


<h2>Day 36: 19th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about tfidf representation and saw how to implement in sklearn and starting a project in text learning</p>
<h4>Thoughts:</h4>
<p>Need to apply all learnt concepts in project</p>
<hr>


<h2>Day 37: 20th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Completed the project successfully that takes a email and does the preprocessing </p>
<h4>Thoughts:</h4>
<p>Need to learn more in nltk. so wanted to start nltk tutorials on youtube</p>
<hr>


<h2>Day 38: 21st September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about word tokenizers, sentence tokenizers and stop words in nltk</p>
<h4>Thoughts:</h4>
<p>Got interested in nltk, so started youtube videos from sentdex. They are really cool!!</p>
<hr>



<h2>Day 39: 22nd September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about Stemming and used Porter stemmer and next learnt part of speech tagging</p>
<h4>Thoughts:</h4>
<p>Getting so much interest in NLP, with the concepts learnt will do a project on creating a dictionary and part of speech tagging using PyQt</p>
<hr>



<h2>Day 40: 23rd September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about Chunking and Chinking and some regular expressions and done name phrase chunking on some text</p>
<h4>Thoughts:</h4>
<p>It's really confusing to learn chunking, took too much time, and hard to understand regular expressions. But anyway understood some good concepts</p>
<hr>


<h2>Day 41: 24th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Studied a lot about Named Entity recognition, implemented that, and read about IOB representations</p>
<h4>Thoughts:</h4>
<p>Named Entity Recognition is very important but sometimes it misclassifies the tags. may be I should learn spaCy in some free time</p>
<hr>



<h2>Day 42: 25th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Understood how to use different corpora and learnt about lemmatizing</p>
<h4>Thoughts:</h4>
<p>Lemmatizing looks better than stemming and working with huge corpora is good</p>
<hr>


<h2>Day 43: 26th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about wordnet, to get synonyms and antonyms of word, to get definitions and examples and also computing the similarity of two words using wordnet</p>
<h4>Thoughts:</h4>
<p>Wordnet is huge and got confused between synsets and lemmas but very useful in nlp and we can do a lot with wordnet</p>
<hr>


<h2>Day 44: 27th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Started doing the project of movie review classification whether positive or negative. completed some portion of importing and storing in lists</p>
<h4>Thoughts:</h4>
<p>Excited in doing projects as most of the learning happens there</p>
<hr>


<h2>Day 45: 28th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Completed the projet of movie review classification using NaiveBayes and pickled the classifier. Getting an accuracy of nearly 80</p>
<h4>Thoughts:</h4>
<p>Now feeling that I have to do more and more projects in NLP</p>
<hr>


<h2>Day 46: 29th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Started doing real world project on movie review classification and got data from IMDB. just cleaned the data and arranged</p>
<h4>Thoughts:</h4>
<p>Wanted to do this project more user friendly and easy to use.</p>
<hr>


<h2>Day 47: 30th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Formatted data according to required format and removed the useless words and cleaned the data.</p>
<h4>Thoughts:</h4>
<p>The most toughest job is data cleaning and successfully completed that. next need to train and test on data</p>
<hr>



<h2>Day 48: 1st October 2018</h2>
<h4>Todays Progress:</h4>
<p>Revised and learnt some concepts in numpy from youtube videos.</p>
<h4>Thoughts:</h4>
<p>Text classification is under process and without wasting time I wanted to start another machine learning tutorial.</p>
<hr>


<h2>Day 49: 2nd October 2018</h2>
<h4>Todays Progress:</h4>
<p>Started learning pandas from <a href="https://www.youtube.com/playlist?list=PLeo1K3hjS3uuASpe-1LjfG5f14Bnozjwy">here</a>. Completed learning DataFrame basics, ways of creating data frames and different functions to read and write csv and excel files</p>
<h4>Thoughts:</h4>
<p>As pandas is very important in data analysis, started learning it in depth.</p>
<hr>


<h2>Day 50: 3rd October 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt how to handle missing data and various methods to handle them, to use replace function to replace special characters</p>
<h4>Thoughts:</h4>
<p>Now feeling confident as I have completed handling missing data as it is the most important in data munging but still have so much to study in pandas.</p>
<hr>


<h2>Day 51: 4th October 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt how to handle missing data using sklearn's Imputer, and also how to encode categorical data using sklearn</p>
<h4>Thoughts:</h4>
<p>Getting into Data preprocessing so that I can use these in future machine learning models and still have so much to study in Data Preprocessing</p>
<hr>


<h2>Day 52: 5th October 2018</h2>
<h4>Todays Progress:</h4>
<p>Studied about feature scaling like standardisation and normalization and learnt how to implement them in sklearn and also learnt how to split the test and train data</p>
<h4>Thoughts:</h4>
<p>Completed most of the steps in data preprocessing and got ready for starting machine learning topics</p>
<hr>


<h2>Day 53: 6th October 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt the Simple Linear Regression and also completed the project predcting the salaries based on years of experience</p>
<h4>Thoughts:</h4>
<p>Super excited to start ML from basics, and completed the project, need to learn about more Regression Models</p>
<hr>

<h2>Day 54: 7th October 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about Multiple Linear Regression, Homoscedasticity, Multicollinearity and Dummy variable trap</p>
<h4>Thoughts:</h4>
<p>studied a lot of theory regarding MLR, now need to start a project</p>
<hr>

<h2>Day 55: 8th October 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about methods of building a model, like backward eliminaton, forward selection, bidirectional elimination</p>
<h4>Thoughts:</h4>
<p>Took so much time to understand, as these concepts are very complex.</p>
<hr>

<h2>Day 56: 9th October 2018</h2>
<h4>Todays Progress:</h4>
<p>Successfully completed the project on Multiple Linear Regression, that could predict the profit of a start up based on the amount they have spent on marketing, R&D etc.</p>
<h4>Thoughts:</h4>
<p>Project is working fine, but need to use backward elimination to eliminate the preditors that are not very important</p>
<hr>


<h2>Day 57: 10th October 2018</h2>
<h4>Todays Progress:</h4>
<p>Hurray!! Used backward elimination to eliminate the features that are statistically less significant. Now predicted results are more closer to the actual results</p>
<h4>Thoughts:</h4>
<p>Backward elimination was very confusing, but after watching lot of tutorials finally got good understanding of that. and yeah successfully completed the project.</p>
<hr>


<h2>Day 58: 11th October 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt Polynomial Regression and learnt how to use it with linear regression, completed the project on predicting the salary of employee based on their level using Polynomial Regression</p>
<h4>Thoughts:</h4>
<p>Polynomial regression is just slight extention of multiple linear regression but quite useful as real world data is not linear.</p>
<hr>


<h2>Day 59: 12th October 2018</h2>
<h4>Todays Progress:</h4>
<p>Studied about Support Vector Regression and completed the project that could predict the salary of employee based their level</p>
<h4>Thoughts:</h4>
<p>SVR was very easy to understand and implement but a bit confusing in gamma and C parameters</p>
<hr>

<h2>Day 60: 13th October 2018</h2>
<h4>Todays Progress:</h4>
<p>Studied about Decision tree regression and also completed the project that could predict the salary of employee based on their position level using Decision Tree Regression</p>
<h4>Thoughts:</h4>
<p>Decision tree is not giving very accurate results and hence need to learn some ensemble methods</p>
<hr>


<h2>Day 61: 14th October 2018</h2>
<h4>Todays Progress:</h4>
<p>Studied about Random forest regression regression and also completed the project that could predict the salary of employee based on their position level using Random Forest Regression</p>
<h4>Thoughts:</h4>
<p>Hmm..The accuracy has increased compared to Normal Decision trees and is very robust.</p>
<hr>

<h2>Day 62: 15th October 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about Logistic Regression and the mathematical changes from linear regression and also the evaluation metrics for classification problems.</p>
<h4>Thoughts:</h4>
<p>Moving from Regression to Classification, started logistic regression and completed the theory and next will do a project.</p>
<hr>


<h2>Day 63: 16th October 2018</h2>
<h4>Todays Progress:</h4>
<p>Successfully completed the project that classifies the users whether they will buy SUV based on their age and salary, gives and accuracy of 89%</p>
<h4>Thoughts:</h4>
<p>Doing projects is more interesting, and next going to study about KNN classifier</p>
<hr>

<h2>Day 64: 17th October 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about knn classifier and completed the project same project as logistic regression but got an accuracy of 93%</p>
<h4>Thoughts:</h4>
<p>KNN got more accuracy because it is non linear model, and hence quite useful.</p>
<hr>


<h2>Day 65: 18th October 2018</h2>
<h4>Todays Progress:</h4>
<p>Completed learning about linear SVM and also done the same project as logistic regression and got an accuracy of 90%</p>
<h4>Thoughts:</h4>
<p>Accuracy was quite low because I have used linear SVM, will study about various kernels and try to improve that</p>
<hr>

<h2>Day 66: 19th October 2018</h2>
<h4>Todays Progress:</h4>
<p>Completed the project on diabetes classification using KNN, but the model is giving low accuracy and needs to handle data carefully</p>
<h4>Thoughts:</h4>
<p>Handling the data and trying to build with other models too</p>
<hr>

<h2>Day 67: 20th October 2018</h2>
<h4>Todays Progress:</h4>
<p>YaY!! Successfully completed the project and working great with an accuracy of nearly 81% using Logistic Regression</p>
<h4>Thoughts:</h4>
<p>Data had no null values but has zero values so handled them and used Logistic Regression which is giving good accuracy</p>
<h4>Link to Work:</h4>
<p><a href="https://github.com/SurajChinna/Diabetes-Classification">GitHub Page</a></p>
<hr>

<h2>Day 68: 21st October 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about various kernels in SVM like rbf, sigmoid and polynomial. Understood the kernel trick and how non linear classification is done</p>
<h4>Thoughts:</h4>
<p>Understood the concepts and now improving the project that was done using linear SVM</p>
<hr>



<h2>Day 69: 22nd October 2018</h2>
<h4>Todays Progress:</h4>
<p>Included the kernel SVM file for the previous repo. kernel SVM with rbf kernel gives great accuracy of 93%</p>
<h4>Thoughts:</h4>
<p>The kernel SVM works great but is really broad and complex. confused with various kernels but understood basic kernels</p>
<h4>Link to Work:</h4>
<p><a href="https://github.com/SurajChinna/SVM-for-classification-using-social-media-ads">GitHub Repo</a></p>
<hr>
