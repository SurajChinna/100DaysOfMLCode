<h1>100 Days of ML Code</h1>
<hr>
<h2>Day 0: 14th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Basic Setup of environment and enrollment in Udacity's Machine Learning intro course and completed Introduction videos.</p>
<h4>Thoughts:</h4>
<p>The course is amazing and excited about 100 days of ML Code.</p>
<h4>Link of Work:</h4>
<p>Just enrolled in this course: https://in.udacity.com/course/intro-to-machine-learning--ud120-india</p>
<hr>

<h2>Day 1: 15th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt how exactly gradient descent works with mathematical derivations and also learnt Naive bayes for classification and implemented using sklearn</p>
<h4>Thoughts:</h4>
<p>Gone crazy in mathematical proofs for gradient descent but very important to understand why we are doing everything and next sklearn is very easy to use.</p>
<hr>

<h2>Day 2: 16th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt and solved problems on Bayes rule and learnt it's applications. Started developing the mini project on naive bayes.</p>
<h4>Thoughts:</h4>
<p>Once J.K.Rowling published a book name under false author name but the computers were able to identify that it was her and it's exciting to know that it can be done using naive bayes.</p>
<hr>

<h2>Day 3: 17th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about McCulloh pits neuron, their advantages and disadvantages and moved on to perceptron and also learnt perceptron algorithm</p>
<h4>Thoughts:</h4>
<p>Thought that I could the complete project started on day:2 but I couldn't as the dataset was huge, so learnt moved onto deep learning and learnt the perceptron stuff.</p>
<hr>

<h2>Day 4: 18th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Set up the python 2.7 environment ans finally completed the mini project on naive bayes and acheived an accuracy of 97.32%</p>
<h4>Thoughts:</h4>
<p>The dataset was huge and it took much time to download and extract but it is good to do some mini projects as they clear the concepts.</p>
<hr>

<h2>Day 5: 19th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about linearly saperable boolean functions, Sigmoid neuron, the typical machine learning setup.</p>
<h4>Thoughts:</h4>
<p>Understood the need for using sigmoid neuron, and the basic machine learning things needed to solve any problem.</p>
<hr>

<h2>Day 6: 20th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about feed forward forward neural networks and how to learn the parameters the feed forward neural networks.</p>
<h4>Thoughts:</h4>
<p>It's interesting to learn how to apply gradient descent for multilayer neural networks and the proofs.</p>
<hr>

<h2>Day 7: 21st August 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about Entropy, Cross Entropy and their derivations and understood which loss function to choose depending on outputs.</p>
<h4>Thoughts:</h4>
<p>The deeper you go into deep learning the more it is confusing. It took so much time to understand the difference between entropy and cross entropy.</p>
<hr>


<h2>Day 8: 22nd August 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt the backpropagation intuition and the derivations of the gradent with respect to the output units.</p>
<h4>Thoughts:</h4>
<p>Really exciting to know how exaclty backpropagation works with mathematical derivations, but just completed on output layer need to still calculate with respect to hidden layers, weights and biases</p>
<hr>


<h2>Day 9: 23rd August 2018</h2>
<h4>Todays Progress:</h4>
<p>Started learning SVM's in Udacity's Intro to Machine Learning Course..</p>
<h4>Thoughts:</h4>
<p>I really have a lot of confusion with SVM's, need to understand them better.</p>
<hr>


<h2>Day 10: 24th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about linear SVM and coded using SKlearn.</p>
<h4>Thoughts:</h4>
<p>The linear svm is easy to understand but need to know about several parameters used in it.</p>
<hr>

<h2>Day 11: 25th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Completed learning SVM including non-linear, and also learnt about gamma and C parameter.</p>
<h4>Thoughts:</h4>
<p>Interesting to learn about various kernels, started doing a project on SVM.</p>
<hr>


<h2>Day 12: 26th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Successfully completed project using SVM, the same project done using naive bayes but svm gives an accuray more than 99%.</p>
<h4>Thoughts:</h4>
<p>SVM's really take a lot of time in training but ofcourse gave a good accuracy.</p>
<hr>

<h2>Day 13: 27th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Started learning Decision trees from Udacity's Intro to Machine Learning course, learnt about basic decision tree and coded using skklearn.</p>
<h4>Thoughts:</h4>
<p>Decision trees are more prone to overfitting, need to learn if there is any way to reduce that.</p>
<hr>

<h2>Day 14: 28th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about Entropy, Information Gain, Bias and Variance. Started building the project on Decision Trees</p>
<h4>Thoughts:</h4>
<p>Understood decision trees very clearly, they are just simple like if else blocks.</p>
<hr>

<h2>Day 15: 29th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Successfully completed the project on Decision trees(the same project done using naive bayes) and got an accuracy of 97%</p>
<h4>Thoughts:</h4>
<p>Decision trees might be overfitting if we have more features, but in general gives good results</p>
<hr>



<h2>Day 16: 30th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Intersted in developing a project on Breast cancer prediction, so started learning Flask to build backend</p>
<h4>Thoughts:</h4>
<p>Flask is very easy to learn and yet powerful, learnt basics quickly</p>
<hr>



<h2>Day 17: 31th August 2018</h2>
<h4>Todays Progress:</h4>
<p>Started working on Breast cancer prediction, collected the data and done some preprocessing</p>
<h4>Thoughts:</h4>
<p>Lucky that most of the data is good, so made it easy to process</p>
<h4>Link to Data:</h4>
<p>https://www.kaggle.com/uciml/breast-cancer-wisconsin-data</p>
<hr>



<h2>Day 18: 1st September 2018</h2>
<h4>Todays Progress:</h4>
<p>Built complte Prediction using SVM and also built an API to make the requests to server</p>
<h4>Thoughts:</h4>
<p>Too complex in this step, tried with ANN but it is over fitting the model so used SVM</p>
<hr>



<h2>Day 19: 2nd September 2018</h2>
<h4>Todays Progress:</h4>
<p>Successfully completed the project including the frontend with bootstrap, working great and yields an accuracy of more than 98%</p>
<h4>Thoughts:</h4>
<p>It was really a wonderful experience to build the complete project. so happy</p>
<h4>Link to Work:</h4>
<p>https://github.com/SurajChinna/Breast-Cancer-Prediction<p>
<hr>


<h2>Day 20: 3rd September 2018</h2>
<h4>Todays Progress:</h4>
<p>Started building a project that could predict the relationship between two sentences of a paragraph and returns the percentage using wordnet</p>
<h4>Thoughts:</h4>
<p>I really know nothing about nltk and wordnet but still trying to build a project</p>
<hr>

<h2>Day 21: 4th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Woo! Successfully completed the project but that is not accurate but doing well</p>
<h4>Thoughts:</h4>
<p>Felt really tough to jump into project without knowing anythig but somehow managed to complete.</p>
<h4>Link to Work:</h4>
<p>https://github.com/SurajChinna/Breast-Cancer-Prediction<p>
<hr>


<h2>Day 22: 5th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt the basic concepts of KNN and how it works</p>
<h4>Thoughts:</h4>
<p>KNN is pretty easy just some math.</p>
<hr>


<h2>Day 23: 6th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Back into Udacity's Intro to Machine Learning course, started lesson datasets and learning about enron</p>
<h4>Thoughts:</h4>
<p>Enron was a huge organisation that went bankrupt and it is interesting to study the reasons of failure</p>
<hr>


<h2>Day 24: 7th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Just analysed the data-set of enron and various features</p>
<h4>Thoughts:</h4>
<p>Finally, done with enron and need to start Regression</p>
<hr>



<h2>Day 25: 8th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Started the lesson regression.</p>
<h4>Thoughts:</h4>
<p>Just looked how and where the regression is used.</p>
<hr>

<h2>Day 26: 9th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt in greater detail about regression, various evaluation metrics and differences between regression and classification.</p>
<h4>Thoughts:</h4>
<p>Regression is pretty easy but learnt only linear regression</p>
<hr>

<h2>Day 27: 10th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt evaluation metrics in Regression, and completed a small project that could fit the line between age and salary.</p>
<h4>Thoughts:</h4>
<p>Project was good but there were some outliers that disturbed the line so need to learn about outliers</p>
<hr>


<h2>Day 28: 11th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt some basic stuff about outliers and a simple algo to remove them.</p>
<h4>Thoughts:</h4>
<p>Outliers are really disturbing..need to do some project</p>
<hr>

<h2>Day 29: 12th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt and Written a Small practical code to identify and also remove outliers.</p>
<h4>Thoughts:</h4>
<p>It's a good experience to check and remove the outliers.</p>
<hr>


<h2>Day 30: 13th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Understood the KMeans algorithm for clustering and its limitations.</p>
<h4>Thoughts:</h4>
<p>KMeans is really basic but it makes a lot of mistakes due to initialisiations of centroids.</p>
<hr>


<h2>Day 31: 14th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Got more idea about KMeans and completed the mini project in clustering.</p>
<h4>Thoughts:</h4>
<p>need to learn feature scaling.</p>
<hr>


<h2>Day 32: 15th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Started Feature Scaling lesson in Udacity's Intro to Machine Learning course. Learnt what is feature scaling and it's implementation in sklearn</p>
<h4>Thoughts:</h4>
<p>Found feature scaling as a very important step for some algorithms like SVM and KMeans clustering.</p>
<hr>


<h2>Day 33: 16th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt when to apply feature scaling and completed the mini project on feature scaling</p>
<h4>Thoughts:</h4>
<p>Feature scaling can be confusing but pretty interesting.</p>
<hr>


<h2>Day 34: 17th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Started Text Learning lesson in Udacity and learnt about bag of words and how to represent them in sklearn</p>
<h4>Thoughts:</h4>
<p>It's really hard to deal with language and a lot of confusion. I have to dig deeper</p>
<hr>


<h2>Day 35: 18th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about stemmers and also learnt how to use them in sklearn and implemented SnowballStemmer</p>
<h4>Thoughts:</h4>
<p>feeling confident as going more into text learning</p>
<hr>


<h2>Day 36: 19th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about tfidf representation and saw how to implement in sklearn and starting a project in text learning</p>
<h4>Thoughts:</h4>
<p>Need to apply all learnt concepts in project</p>
<hr>


<h2>Day 37: 20th September 2018</h2>
<h4>Todays Progress:</h4>
<p>Completed the project successfully that takes a email and does the preprocessing </p>
<h4>Thoughts:</h4>
<p>Need to learn more in nltk. so wanted to start nltk tutorials on youtube</p>
<hr>


<h2>Day 38: 21st September 2018</h2>
<h4>Todays Progress:</h4>
<p>Learnt about word tokenizers, sentence tokenizers and stop words in nltk</p>
<h4>Thoughts:</h4>
<p>Got interested in nltk, so started youtube videos from sentdex. They are really cool!!</p>
<hr>
